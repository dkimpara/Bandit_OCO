\section{Projected Gradient Descent with $k$ queries per round}
\input{alg-generic.tex}\newpage

In this section we present a no-regret result for any algorithm that is an instantiation of Algorithm \ref{alg:generic} for some $k$ and where its randomized gradient estimate satisfies boundedness and closeness of its expectation to the true gradient. We assume the reader is familiar with OGD.

We first explain the algorithm. It plays $k$ actions, constructs a gradient estimate $\tildegt$ from its $k$ actions in round $t$ and performs the OGD step to produce the next action $x_{t+1}$:

$$x_{t+1} = \proj[(1-\xi)\K]{(x_t - \eta \tilde{g}_t)},$$

where $\xi \in (0,1)$ and $(1-\xi)\K$ is shorthand for $\{(1-\xi)x : x \in \K\}$. Note that our gradient estimators will randomly query around the action $x_t$ in order to estimate the gradient. Thus the projection is made onto the shrunk set to ensure that the random queries around the point $x_{t+1}$ belong to $\K$. For any $x \in (1-\K)$ and any unit vector $u$ it holds that $(x+\delta u ) \in \K$ for any $\delta \in [0, \xi r]$ \citep{flaxman2004online}. 




We now present the main result. But first, we need two Lemmas the first is the dynamic regret bound of OGD and the second is the difference in regret between playing $x_t$ on $\K$ and $\{y_{t,i}\}_{i=1}^k$ on $(1-\xi) \K$.
\dk{check $\eta$}
\begin{lemma} \citep{mokhtari2016online}.\label{lem:OGD}
	Assume that the functions $h_t$ are strongly convex and $L$-smooth. Assume further that the gradient norms are bounded and the step size is chosen such that $\eta \leq 1/L$. Then, the dynamic regret $Regret_T^d$ for the sequence of actions $x_t$ generated by OGD is bounded by
	
	$$Regret_T^d(OGD, G):= \sumt h_t(x_t) - \sumt \min_{\xst\in \K} h_t(\xst) \leq G K_1 \sum_{t=2}^T \norm{\xst - x_{t-1}^*} + G K_2$$
	
	where the constants $K_1$ and $K_2$ are explicitly given by
	
	$$K_1 := \frac{\norm{x_1 - x_1^*} - \rho \norm{x_T - x_T^*}}{(1-\rho)}, ~~ K_2 := \frac{1}{1-\rho}.$$
	
	Where $0 \leq \rho := (1-\eta\mu) ^ {1/2} < 0$. Is our linear convergence constant.
\end{lemma}

\begin{lemma} \label{lem:2}
	For any point $x \in \K$,
	
	$$\frac{1}{k} \sumk \lt(y_{t,i}) - \ell_t(x) \leq  \lt(x_t) -  \lt((1-\xi)x) + G\delta + GD\xi.$$
	
\end{lemma}
 
\begin{proof}
	By assumption of Lipschitz continuity,
	
	$$\lt(y_{t,i}) \leq \lt(x_t) + G \delta.$$
	
	We also have that by the Lipschitz property and $\norm{x} \leq D$, for all $x \in \K$,
	$$\lt((1-\xi)x) \leq \lt(x) + GD\xi.$$
	
	Combining the above two inequalities we get
	$$\frac{1}{k} \sumk \lt(y_{t,i}) + \lt((1-\xi)x) \leq \lt(x_t) + \lt(x) +  G \delta + GD\xi.$$
	
	Rearranging terms gives us the Lemma.
	
	
\end{proof}


\begin{theorem} \label{thm:one}
	Assume that the assumptions hold. Suppose on round $t$ the algorithm plays $k$ random queries $y_{t,1}, ..., y_{t,k}$, constructs a gradient estimator $\tilde{g}_t = g(y_{t,1}, ..., y_{t,k})$ and uses the the algorithmic step $x_{t+1} = \proj[(1-\xi)\K]{(x_t - \eta \tilde{g}_t)}$ with $\eta \leq \frac{1}{2G_1}$, $\delta = \frac{\log(T)}{T}$, and $\xi = \frac{\delta}{r}$. If the gradient estimator satisfies the following conditions for all $t \geq 1$:
	
	\begin{enumerate}
		\item $\norm{x_t - y_{t,i}} \leq \delta \text{ for } i = 1, ... k$.
		\item $\norm{\tildegt} \leq G_1$ for some constant $G_1$.
		\item $\norm{\E_t \tildegt - \glt(x_t)} \leq c\delta$ for some constant $c$. 
		 
	\end{enumerate}
	Then for any sequence $\{\xst\}_{t=1}^{T}, \xst\in\K$ we have
	
	$$\E \frac{1}{k} \sumt \sumk \lt(y_{t,i}) - \E \sumt \min_{\xst\in \K}\ell_t(\xst) \leq G_1 K_1 \sum_{t=2}^T \norm{\xst - x_{t-1}^*} + G_1 K_2 + G \log(T)\big(1 + 2c + \frac{D}{r}\big).$$
	
	where the constants $K_1$ and $K_2$ are explicitly given by
	
	$$K_1 := \frac{\norm{x_1 - x_1^*} - \rho \norm{x_T - x_T^*}}{(1-\rho)}, ~~ K_2 := \frac{1}{1-\rho}.$$
	
	Where $0 \leq \rho := (1-\eta\mu) ^ {1/2} < 0$ is our linear convergence constant.
	

\end{theorem}


\begin{proof}
	Start by defining $h_t(x) = \lt(x) + (\tildegt - \glt(x))^\intercal x$. Then $h_t$ has the same convexity properties as $\lt$ and is $L_1$-smooth. Note also that $\nabla h_t(x_t) = \tildegt$. So we can pretend that the algorithm is actually performing deterministic gradient descent, as if with full information, on the functions $h_t$ restricted to $(1-\xi) \K$. Using the OGD regret bound from Lemma \ref{lem:OGD} we have that since $\nabla h_t(x_t) = \tildegt$ and hence $\norm{\tildegt} \leq G_1$ (So $h_t$ is $2G_1$-smooth since $\nabla h_t$ is $2G_1$-Lipschitz),
	 
	$$\sumt h_t(x_t) - \sumt h_t(\xst) \leq G_1 K_1 \sum_{t=2}^T \norm{\xst - x_{t-1}^*} + 2G_1 K_2 := Regret_{T}^d(OGD, G_1).$$ 
	
	Then taking expectations,
	
	\begin{align*}
		\E \sumt [\lt(x_t) - \lt(\xst)] &= \E \sumt [h_t(x_t) - h_t(\xst)] + \E \sumt[\lt(x_t) - h_t(x_t) - \lt(\xst) + h_t(\xst)] \\
		&\leq Regret_{T}^d(OGD, G_1) + \E \sumt (\E_t \tildegt - \glt(x_t))^\intercal(x_t - \xst)\\
		& \leq Regret_{T}^d(OGD, G_1) + 2c\delta DT.
	\end{align*}
	
	Where the first inequality is by the convexity of $\ell_t$ and $h_t$. Now we use Lemma \ref{lem:2} and obtain
	
	$$\E \frac{1}{k} \sumt \sumk \lt(y_{t,i}) - \E \sumt \min_{\xst\in \K}\ell_t(\xst) \leq Regret_{T}^d(OGD, G_1) + 2c\delta DT + TG\delta + GDT\xi.$$
	
	To finish the proof, plug in the values for $\delta$ and $\xi$.
	
\end{proof}





